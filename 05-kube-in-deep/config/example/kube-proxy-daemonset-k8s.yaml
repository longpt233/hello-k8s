apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2024-11-06T07:36:22Z"
  generateName: kube-proxy-
  labels:
    controller-revision-hash: 6d47dfb59b
    k8s-app: kube-proxy
    pod-template-generation: "3"
  name: kube-proxy-smf7s
  namespace: kube-system
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: DaemonSet
    name: kube-proxy
    uid: d2fc1b28-60e7-436b-b07e-abaa9e0ac1a0
  resourceVersion: "224613"
  uid: fd755b1d-abb8-481f-8581-7dcb2976a199
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchFields:
          - key: metadata.name
            operator: In
            values:
            - vupc
  containers:
  - command:
    - /usr/local/bin/kube-proxy
    - --config=/var/lib/kube-proxy/config.conf
    - --hostname-override=$(NODE_NAME)
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: no_proxy
      value: 127.0.0.1,10.208.164.167,localhost,10.208.164.173
    - name: ftp_proxy
      value: http://10.208.164.185:9999/
    - name: https_proxy
      value: http://10.208.164.185:9999/
    - name: http_proxy
      value: http://10.208.164.185:9999/
    image: registry.k8s.io/kube-proxy:v1.28.15
    imagePullPolicy: IfNotPresent
    name: kube-proxy
    resources: {}
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/kube-proxy
      name: kube-proxy
    - mountPath: /run/xtables.lock
      name: xtables-lock
    - mountPath: /lib/modules
      name: lib-modules
      readOnly: true
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vnrz4
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  nodeName: vupc
  nodeSelector:
    kubernetes.io/os: linux
  preemptionPolicy: PreemptLowerPriority
  priority: 2000001000
  priorityClassName: system-node-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: kube-proxy
  serviceAccountName: kube-proxy
  terminationGracePeriodSeconds: 30
  tolerations:
  - operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/disk-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/pid-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/unschedulable
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/network-unavailable
    operator: Exists
  volumes:
  - configMap:
      defaultMode: 420
      name: kube-proxy
    name: kube-proxy
  - hostPath:
      path: /run/xtables.lock
      type: FileOrCreate
    name: xtables-lock
  - hostPath:
      path: /lib/modules
      type: ""
    name: lib-modules
  - name: kube-api-access-vnrz4
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-11-06T07:36:22Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-11-06T07:40:33Z"
    message: 'containers with unready status: [kube-proxy]'
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-11-06T07:40:33Z"
    message: 'containers with unready status: [kube-proxy]'
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-11-06T07:36:22Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://053a2c12c04e13f2b47412f0fecc1d8e33bab1febe5d2a74535600013b7e37da
    image: registry.k8s.io/kube-proxy:v1.28.15
    imageID: registry.k8s.io/kube-proxy@sha256:8e039a309ca0dc220e6d4350f78d96d1c4c76dd7444354a3ea6142a890ae8ae5
    lastState:
      terminated:
        containerID: containerd://053a2c12c04e13f2b47412f0fecc1d8e33bab1febe5d2a74535600013b7e37da
        exitCode: 2
        finishedAt: "2024-11-06T07:40:32Z"
        reason: Error
        startedAt: "2024-11-06T07:39:13Z"
    name: kube-proxy
    ready: false
    restartCount: 2
    started: false
    state:
      waiting:
        message: back-off 20s restarting failed container=kube-proxy pod=kube-proxy-smf7s_kube-system(fd755b1d-abb8-481f-8581-7dcb2976a199)
        reason: CrashLoopBackOff
  hostIP: 10.208.164.173
  phase: Running
  podIP: 10.208.164.173
  podIPs:
  - ip: 10.208.164.173
  qosClass: BestEffort
  startTime: "2024-11-06T07:36:22Z"
